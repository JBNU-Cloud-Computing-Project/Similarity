"""
ìœ ì‚¬ë„ ê³„ì‚° ëª¨ë“ˆ
Phase 1+2: ì˜ë¯¸(Semantic) + ê´€ê³„(Relational) + í˜•íƒœ(Formative)
"""

import logging
from typing import Dict, Tuple
import numpy as np
from sentence_transformers import SentenceTransformer
from transformers import pipeline
import jamo
import re

logger = logging.getLogger(__name__)


class SimilarityCalculator:
    """ìœ ì‚¬ë„ ê³„ì‚° í´ë˜ìŠ¤"""
    
    def __init__(self, semantic_model_name: str, nli_model_name: str):
        """
        Args:
            semantic_model_name: ì˜ë¯¸ ì„ë² ë”© ëª¨ë¸ ì´ë¦„
            nli_model_name: NLI ëª¨ë¸ ì´ë¦„
        """
        logger.info("ëª¨ë¸ ë¡œë”© ì‹œì‘...")
        
        # ì˜ë¯¸ ìœ ì‚¬ë„ ëª¨ë¸ (ë¬¸ì¥ ì„ë² ë”©)
        self.semantic_model = SentenceTransformer(semantic_model_name)
        logger.info(f"âœ… Semantic ëª¨ë¸ ë¡œë”© ì™„ë£Œ: {semantic_model_name}")
        
        # ê´€ê³„ ìœ ì‚¬ë„ ëª¨ë¸ (NLI)
        self.nli_pipeline = pipeline(
            "text-classification",
            model=nli_model_name,
            device=-1  # CPU ì‚¬ìš© (GPU: 0)
        )
        logger.info(f"âœ… NLI ëª¨ë¸ ë¡œë”© ì™„ë£Œ: {nli_model_name}")
        
        logger.info("ğŸš€ ëª¨ë“  ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
    
    def normalize_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì •ê·œí™”"""
        # ì†Œë¬¸ì ë³€í™˜
        text = text.lower()
        # ê³µë°± ì •ë¦¬
        text = re.sub(r'\s+', '', text)
        # íŠ¹ìˆ˜ë¬¸ì ì œê±°
        text = re.sub(r'[^\w\sê°€-í£]', '', text)
        return text.strip()
    
    def calculate_semantic_similarity(self, input_text: str, answer: str) -> float:
        """
        ì˜ë¯¸ ìœ ì‚¬ë„ ê³„ì‚° (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
        
        Args:
            input_text: ì‚¬ìš©ì ì…ë ¥
            answer: ì •ë‹µ
            
        Returns:
            0.0 ~ 1.0 ì‚¬ì´ì˜ ìœ ì‚¬ë„
        """
        # ì„ë² ë”© ìƒì„±
        embeddings = self.semantic_model.encode([input_text, answer])
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        cosine_sim = np.dot(embeddings[0], embeddings[1]) / (
            np.linalg.norm(embeddings[0]) * np.linalg.norm(embeddings[1])
        )
        
        # -1 ~ 1 ë²”ìœ„ë¥¼ 0 ~ 1ë¡œ ë³€í™˜
        similarity = (cosine_sim + 1) / 2
        
        return float(similarity)
    
    def calculate_relational_similarity(
        self, 
        input_text: str, 
        answer: str,
        templates: list,
        contradiction_templates: list
    ) -> Tuple[float, float]:
        """
        ê´€ê³„ ìœ ì‚¬ë„ ê³„ì‚° (NLI ê¸°ë°˜)
        
        Args:
            input_text: ì‚¬ìš©ì ì…ë ¥
            answer: ì •ë‹µ
            templates: ê¸ì • í…œí”Œë¦¿ ë¦¬ìŠ¤íŠ¸
            contradiction_templates: ë°˜ì˜ í…œí”Œë¦¿ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            (ê´€ê³„ ì ìˆ˜, ë°˜ì˜ì–´ ì ìˆ˜) íŠœí”Œ
        """
        entailment_scores = []
        
        # ê¸ì • í…œí”Œë¦¿ìœ¼ë¡œ ê´€ê³„ ì ìˆ˜ ê³„ì‚°
        for template in templates:
            hypothesis = template.format(input=input_text, answer=answer)
            
            result = self.nli_pipeline(hypothesis)[0]
            
            # entailment í™•ë¥  ì¶”ì¶œ
            if result['label'] == 'entailment':
                entailment_scores.append(result['score'])
            elif result['label'] == 'neutral':
                entailment_scores.append(result['score'] * 0.5)
            else:  # contradiction
                entailment_scores.append(0.0)
        
        # í‰ê·  ê´€ê³„ ì ìˆ˜
        relation_score = np.mean(entailment_scores) if entailment_scores else 0.0
        
        # ë°˜ì˜ì–´ ì ìˆ˜ ê³„ì‚°
        contradiction_scores = []
        for template in contradiction_templates:
            hypothesis = template.format(input=input_text, answer=answer)
            
            result = self.nli_pipeline(hypothesis)[0]
            
            if result['label'] == 'entailment':
                contradiction_scores.append(result['score'])
        
        # ìµœëŒ€ ë°˜ì˜ì–´ ì ìˆ˜
        contradiction_score = max(contradiction_scores) if contradiction_scores else 0.0
        
        return float(relation_score), float(contradiction_score)
    
    def analyze_relationship_type(
        self,
        input_text: str,
        answer: str,
        relationship_templates: Dict[str, str]
    ) -> Tuple[str, float]:
        """
        ì…ë ¥ê³¼ ì •ë‹µ ê°„ ê´€ê³„ ìœ í˜• ë¶„ì„
        
        Args:
            input_text: ì‚¬ìš©ì ì…ë ¥
            answer: ì •ë‹µ
            relationship_templates: ê´€ê³„ ë¶„ì„ í…œí”Œë¦¿ ë”•ì…”ë„ˆë¦¬
            
        Returns:
            (ê´€ê³„ ìœ í˜•, í™•ì‹ ë„) íŠœí”Œ
            ì˜ˆ: ("ì‚¬ëŒê´€ê³„", 0.85)
        """
        relationship_scores = {}
        
        for rel_type, template in relationship_templates.items():
            hypothesis = template.format(input=input_text, answer=answer)
            
            try:
                result = self.nli_pipeline(hypothesis)[0]
                
                # entailment í™•ë¥ ë§Œ ì‚¬ìš©
                if result['label'] == 'entailment':
                    relationship_scores[rel_type] = result['score']
                else:
                    relationship_scores[rel_type] = 0.0
                    
            except Exception as e:
                logger.warning(f"ê´€ê³„ ë¶„ì„ ì˜¤ë¥˜ ({rel_type}): {e}")
                relationship_scores[rel_type] = 0.0
        
        # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ê´€ê³„ ìœ í˜• ë°˜í™˜
        if relationship_scores:
            best_relationship = max(relationship_scores.items(), key=lambda x: x[1])
            return best_relationship[0], best_relationship[1]
        
        return "ì¼ë°˜", 0.0
    
    def calculate_formative_similarity(self, input_text: str, answer: str) -> float:
        """
        í˜•íƒœ ìœ ì‚¬ë„ ê³„ì‚° (ìëª¨ ë¶„í•´ í¸ì§‘ê±°ë¦¬)
        
        Args:
            input_text: ì‚¬ìš©ì ì…ë ¥
            answer: ì •ë‹µ
            
        Returns:
            0.0 ~ 1.0 ì‚¬ì´ì˜ ìœ ì‚¬ë„
        """
        # í•œê¸€ ìëª¨ ë¶„í•´
        input_jamo = jamo.h2j(input_text)
        answer_jamo = jamo.h2j(answer)
        
        # ë ˆë²¤ìŠˆíƒ€ì¸ ê±°ë¦¬ ê³„ì‚°
        distance = self._levenshtein_distance(input_jamo, answer_jamo)
        
        # ìµœëŒ€ ê¸¸ì´ë¡œ ì •ê·œí™”
        max_len = max(len(input_jamo), len(answer_jamo))
        if max_len == 0:
            return 1.0
        
        similarity = 1.0 - (distance / max_len)
        
        return float(max(0.0, similarity))
    
    def _levenshtein_distance(self, s1: str, s2: str) -> int:
        """ë ˆë²¤ìŠˆíƒ€ì¸ í¸ì§‘ê±°ë¦¬ ê³„ì‚°"""
        if len(s1) < len(s2):
            return self._levenshtein_distance(s2, s1)
        
        if len(s2) == 0:
            return len(s1)
        
        previous_row = range(len(s2) + 1)
        for i, c1 in enumerate(s1):
            current_row = [i + 1]
            for j, c2 in enumerate(s2):
                # ì‚½ì…, ì‚­ì œ, ì¹˜í™˜ ë¹„ìš©
                insertions = previous_row[j + 1] + 1
                deletions = current_row[j] + 1
                substitutions = previous_row[j] + (c1 != c2)
                current_row.append(min(insertions, deletions, substitutions))
            previous_row = current_row
        
        return previous_row[-1]
    
    def calculate_combined_similarity(
        self,
        input_text: str,
        answer: str,
        weights: Dict[str, float],
        nli_templates: list,
        contradiction_templates: list
    ) -> Dict[str, float]:
        """
        ì¢…í•© ìœ ì‚¬ë„ ê³„ì‚°
        
        Args:
            input_text: ì‚¬ìš©ì ì…ë ¥
            answer: ì •ë‹µ
            weights: ê°€ì¤‘ì¹˜ ë”•ì…”ë„ˆë¦¬
            nli_templates: NLI ê¸ì • í…œí”Œë¦¿
            contradiction_templates: NLI ë°˜ì˜ í…œí”Œë¦¿
            
        Returns:
            {
                "similarity_score": ìµœì¢… ì ìˆ˜ (0-100),
                "breakdown": {
                    "semantic": ì˜ë¯¸ ì ìˆ˜,
                    "relational": ê´€ê³„ ì ìˆ˜,
                    "formative": í˜•íƒœ ì ìˆ˜,
                    "contradiction": ë°˜ì˜ì–´ ê°ì 
                }
            }
        """
        # í…ìŠ¤íŠ¸ ì •ê·œí™”
        input_normalized = self.normalize_text(input_text)
        answer_normalized = self.normalize_text(answer)
        
        # ì •ë‹µ ì²´í¬
        if input_normalized == answer_normalized:
            return {
                "similarity_score": 100.0,
                "breakdown": {
                    "semantic": 1.0,
                    "relational": 1.0,
                    "formative": 1.0,
                    "contradiction": 0.0
                }
            }
        
        # ê° ìœ ì‚¬ë„ ê³„ì‚°
        semantic_score = self.calculate_semantic_similarity(input_text, answer)
        relation_score, contradiction_score = self.calculate_relational_similarity(
            input_text, answer, nli_templates, contradiction_templates
        )
        formative_score = self.calculate_formative_similarity(input_normalized, answer_normalized)
        
        # ê°€ì¤‘ í‰ê·  ê³„ì‚°
        weighted_score = (
            semantic_score * weights["semantic"] +
            relation_score * weights["relational"] +
            formative_score * weights["formative"]
        )
        
        # ë°˜ì˜ì–´ ê°ì  ì ìš©
        weighted_score = weighted_score - (contradiction_score * 0.15)
        
        # 0~1 ë²”ìœ„ë¡œ í´ë¦¬í•‘
        weighted_score = max(0.0, min(1.0, weighted_score))
        
        # ë°±ë¶„ìœ¨ë¡œ ë³€í™˜
        final_score = weighted_score * 100
        
        return {
            "similarity_score": round(final_score, 2),
            "breakdown": {
                "semantic": round(semantic_score, 4),
                "relational": round(relation_score, 4),
                "formative": round(formative_score, 4),
                "contradiction": round(contradiction_score, 4)
            }
        }